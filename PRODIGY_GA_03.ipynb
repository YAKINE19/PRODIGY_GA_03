{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2730445,"sourceType":"datasetVersion","datasetId":1167113}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#installing the required libraries\n!pip install nltk\n!pip install spacy\n!pip install markovify\n!pip install -m spacy download en","metadata":{"execution":{"iopub.status.busy":"2024-07-06T09:33:01.284121Z","iopub.execute_input":"2024-07-06T09:33:01.284630Z","iopub.status.idle":"2024-07-06T09:33:58.115905Z","shell.execute_reply.started":"2024-07-06T09:33:01.284591Z","shell.execute_reply":"2024-07-06T09:33:58.114079Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\nCollecting markovify\n  Downloading markovify-0.9.4.tar.gz (27 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting unidecode (from markovify)\n  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\nDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: markovify\n  Building wheel for markovify (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18606 sha256=2389a6771f7dca201dd2884da64c6f63c6763f6e8e755c5d63b7c39da49b81c6\n  Stored in directory: /root/.cache/pip/wheels/ca/8c/c5/41413e24c484f883a100c63ca7b3b0362b7c6f6eb6d7c9cc7f\nSuccessfully built markovify\nInstalling collected packages: unidecode, markovify\nSuccessfully installed markovify-0.9.4 unidecode-1.3.8\n\nUsage:   \n  pip install [options] <requirement specifier> [package-index-options] ...\n  pip install [options] -r <requirements file> [package-index-options] ...\n  pip install [options] [-e] <vcs project url> ...\n  pip install [options] [-e] <local project path> ...\n  pip install [options] <archive url/path> ...\n\nno such option: -m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Loading Data:**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport markovify\nimport nltk\nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')\n\nimport pandas as pd\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Connect to the SQLite database\nconn = sqlite3.connect('/kaggle/input/wikibooks-dataset/wikibooks.sqlite')\n\n\n# Load the data into a pandas dataframe\ndf = pd.read_sql_query(\"SELECT * FROM en LIMIT 1000\", conn)\n\n# Concatenate 'body_text' entries into a single string\ndata = ' '.join(df['body_text'].dropna())\n\n# Function for text cleaning\ndef text_cleaner(text):\n    text = re.sub(r'\\[\\d+\\]', '', text)  # Remove citation references like [1], [2], etc.\n    text = re.sub(r'\\n', ' ', text)      # Replace newline characters with spaces\n    text = re.sub(r'\\s+', ' ', text)     # Replace multiple spaces with a single space\n    return text.strip()                  # Strip leading and trailing whitespace\n\n# Clean the dataset\ncleaned_data = text_cleaner(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T09:34:55.136910Z","iopub.execute_input":"2024-07-06T09:34:55.137556Z","iopub.status.idle":"2024-07-06T09:34:56.448217Z","shell.execute_reply.started":"2024-07-06T09:34:55.137520Z","shell.execute_reply":"2024-07-06T09:34:56.446885Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Tokenization and Model Building:**","metadata":{}},{"cell_type":"code","source":"# Tokenize the cleaned data into words\ntokens = word_tokenize(cleaned_data)\n\n# Function to build Markov chain model\ndef build_markov_chain(tokens, n=2):\n    markov_chain = {}\n    for i in range(len(tokens)-n):\n        key = ' '.join(tokens[i:i+n])\n        value = tokens[i+n]\n        if key in markov_chain:\n            markov_chain[key].append(value)\n        else:\n            markov_chain[key] = [value]\n    return markov_chain\n\n# Build the Markov chain model\nmarkov_chain = build_markov_chain(tokens, n=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T09:36:03.053634Z","iopub.execute_input":"2024-07-06T09:36:03.054160Z","iopub.status.idle":"2024-07-06T09:36:22.747887Z","shell.execute_reply.started":"2024-07-06T09:36:03.054120Z","shell.execute_reply":"2024-07-06T09:36:22.746158Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## **Generating Text:**","metadata":{}},{"cell_type":"code","source":"import random\n# Function to generate text using Markov chain\ndef generate_text(markov_chain, seed, length=100):\n    current = seed.split()  # Initial seed\n    text = current.copy()\n\n    while len(text) < length:\n        key = ' '.join(current[-len(seed.split()):])\n        if key in markov_chain:\n            next_word = random.choice(markov_chain[key])\n            text.append(next_word)\n            current.append(next_word)\n        else:\n            break\n\n    return ' '.join(text)\n\n# Seed for text generation\nseed = \"machine learning\"\n\n# Generate text using the Markov chain model\ngenerated_text = generate_text(markov_chain, seed, length=50)\nprint(\"Generated Text:\")\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T09:43:50.017316Z","iopub.execute_input":"2024-07-06T09:43:50.018076Z","iopub.status.idle":"2024-07-06T09:43:50.029951Z","shell.execute_reply.started":"2024-07-06T09:43:50.018038Z","shell.execute_reply":"2024-07-06T09:43:50.028422Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Generated Text:\nmachine learning algorithms for public-key encryption . Read a book , worked to prevent workplace harassment cases reported to the room . Overhead projectors are becoming outdated and contain links to more wide use by consumers in the Moslem World today . This book is on the shelf materials and\n","output_type":"stream"}]},{"cell_type":"code","source":"import spacy\n# Load SpaCy English model\nnlp = spacy.load('en_core_web_sm')\n\n# Define a subclass of markovify.Text that uses SpaCy for part-of-speech tagging\nclass POSifiedText(markovify.Text):\n    def word_split(self, sentence):\n        return ['::'.join((word.orth_, word.pos_)) for word in nlp(sentence)]\n    \n    def word_join(self, words):\n        sentence = ' '.join(word.split('::')[0] for word in words)\n        return sentence\n\n# Create a POSifiedText instance with state_size=3\ngenerator_wikibooks = POSifiedText(cleaned_data, state_size=3)\n\n# Generate sentences using the new generator\nprint(\"Generated Sentences:\")\nfor i in range(5):\n    print(generator_wikibooks.make_sentence())\n\nprint(\"\\nGenerated Short Sentences (max 100 characters):\")\nfor i in range(5):\n    print(generator_wikibooks.make_short_sentence(max_chars=100))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T09:37:36.433922Z","iopub.execute_input":"2024-07-06T09:37:36.434416Z","iopub.status.idle":"2024-07-06T09:43:50.014471Z","shell.execute_reply.started":"2024-07-06T09:37:36.434376Z","shell.execute_reply":"2024-07-06T09:43:50.012840Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Generated Sentences:\nWhat types of information will best illuminate what you are left with is the verb 's i - form  puli .\n?  is used to brew a potion that is used in this book mention could not be available , which means JMOOC is for self - directed learning .\nA weapon is defined by similarities with one or more operating systems together allowing for communication between the islands in the Pacific .\nThe next phase involved the task to establish a chain of communications on our behalf through the United States was not engaged in any major war .\nThe simplest smudging tool is the finger , although care should be used in each successive time the for loop is run through .\n\nGenerated Short Sentences (max 100 characters):\nMy real job is to take a specific course of action , and vice versa .\nThey are much smaller than the prior .\nThe foundation on which the Imperial post office will be represented by a hollow dot .\nThe assembly language code was then fed into the maw of combat .\nFor example you may notice that Mary has zero blocks while others may inflict status effects .\n","output_type":"stream"}]}]}